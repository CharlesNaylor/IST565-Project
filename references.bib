@article{PhysRevLett.120.024102,
  title = {Model-Free Prediction of Large Spatiotemporally Chaotic Systems from Data: A Reservoir Computing Approach},
  author = {Pathak, Jaideep and Hunt, Brian and Girvan, Michelle and Lu, Zhixin and Ott, Edward},
  journal = {Phys. Rev. Lett.},
  volume = {120},
  issue = {2},
  pages = {024102},
  numpages = {5},
  year = {2018},
  month = {Jan},
  publisher = {American Physical Society},
  doi = {10.1103/PhysRevLett.120.024102},
  url = {https://link.aps.org/doi/10.1103/PhysRevLett.120.024102}
}
@electronic{barabasi2002linked,
  added-at = {2012-05-14T20:13:46.000+0200},
  address = {Cambridge, Mass.},
  author = {Barabasi, Albert-Laszlo},
  biburl = {https://www.bibsonomy.org/bibtex/29d6c95f1a97281a7d41abf52d1fc7afb/cscholz},
  description = {Amazon.com: Linked: The New Science of Networks (9780738206677): Albert-laszlo Barabasi, Jennifer Frangos: Books},
  interhash = {dbb8d0d999c2d66544c2aa44464f1314},
  intrahash = {9d6c95f1a97281a7d41abf52d1fc7afb},
  isbn = {9780738206677 0738206679 9780786746965 0786746963},
  keywords = {link prediction sna},
  publisher = {Perseus Pub.},
  refid = {768680724},
  timestamp = {2012-05-14T20:13:47.000+0200},
  title = {Linked the new science of networks},
  url = {http://www.amazon.com/Linked-The-New-Science-Networks/dp/0738206679},
  year = 2002
}
@misc{naylor_GP,
	title={Gaussian Process Regression for FX Forecasting: A Case Study},
	author={Charles Naylor},
	year=2017,
	url={https://charlesnaylor.github.io/gp_regression/},
	urldate={2018-06-15}
}
@Inbook{Luko2012,
author="Luko{\v{s}}evi{\v{c}}ius, Mantas",
editor="Montavon, Gr{\'e}goire
and Orr, Genevi{\`e}ve B.
and M{\"u}ller, Klaus-Robert",
title="A Practical Guide to Applying Echo State Networks",
bookTitle="Neural Networks: Tricks of the Trade: Second Edition",
year="2012",
publisher="Springer Berlin Heidelberg",
address="Berlin, Heidelberg",
pages="659--686",
abstract="Reservoir computing has emerged in the last decade as an alternative to gradient descent methods for training recurrent neural networks. Echo State Network (ESN) is one of the key reservoir computing ``flavors''. While being practical, conceptually simple, and easy to implement, ESNs require some experience and insight to achieve the hailed good performance in many tasks. Here we present practical techniques and recommendations for successfully applying ESNs, as well as some more advanced application-specific modifications.",
isbn="978-3-642-35289-8",
doi="10.1007/978-3-642-35289-8_36",
url="https://doi.org/10.1007/978-3-642-35289-8_36"
}
